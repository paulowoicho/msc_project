{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarization Task - Results and Evaluation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2ee0c9dc049495a9cfa7a4c87e43148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb9bb42dbb4145b997010d6b65816197",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07c3888e35a94209b310bf7c8652879e",
              "IPY_MODEL_9c2b826873ac49fd94693c5341b74754"
            ]
          }
        },
        "bb9bb42dbb4145b997010d6b65816197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07c3888e35a94209b310bf7c8652879e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25fd689c97144c0db80928b007a118ac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1578,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1578,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfdb8acea64e465d98a4f8333532da85"
          }
        },
        "9c2b826873ac49fd94693c5341b74754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85051cd8681c42bfb9410c94423d2808",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 6.36kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79f0680581914aa9a69d08a12a5719ee"
          }
        },
        "25fd689c97144c0db80928b007a118ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfdb8acea64e465d98a4f8333532da85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85051cd8681c42bfb9410c94423d2808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79f0680581914aa9a69d08a12a5719ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fec84906f0134e8aa9ff603612229dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65c1710660f244e1833dc80841074f15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a7c4de3325f4904843b80405883177a",
              "IPY_MODEL_e0b6fdb9eed441ba8122db95aae7b64b"
            ]
          }
        },
        "65c1710660f244e1833dc80841074f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a7c4de3325f4904843b80405883177a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0973e28442994c84973567ee8fe39306",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898822,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898822,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7c871bbfc4245b8afa54afa22bfa60c"
          }
        },
        "e0b6fdb9eed441ba8122db95aae7b64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7db9f49dc74649eebe6431165f0dc7e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 832kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d3e2aae4bc0493b9a0b2365a7bfe85d"
          }
        },
        "0973e28442994c84973567ee8fe39306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7c871bbfc4245b8afa54afa22bfa60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7db9f49dc74649eebe6431165f0dc7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d3e2aae4bc0493b9a0b2365a7bfe85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72e04089282c48fb9dff5382cdbb8ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c7d3a82e22c42e183ac13171d1e49f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef4f5ff6846845c8950732a27d8ec255",
              "IPY_MODEL_3ca4f4edd23f47feb8e789083aef93f5"
            ]
          }
        },
        "6c7d3a82e22c42e183ac13171d1e49f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef4f5ff6846845c8950732a27d8ec255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d18b6608126447b1b12efa20267617ec",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59021576d2aa40f9bf3ebe49b69463d4"
          }
        },
        "3ca4f4edd23f47feb8e789083aef93f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_077f6570fd3e4aeeb7c471f4b31b44f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 612kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2908490d95bf4e9dae82e978d01224af"
          }
        },
        "d18b6608126447b1b12efa20267617ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59021576d2aa40f9bf3ebe49b69463d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "077f6570fd3e4aeeb7c471f4b31b44f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2908490d95bf4e9dae82e978d01224af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6ef7faa74c94b8d951ff5d60308c23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_626591f60e8f4d3ea33d22155353137e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_376cbb73578d4743b95143487c767565",
              "IPY_MODEL_70631ea011104f8ebfaed5889f8ea6ca"
            ]
          }
        },
        "626591f60e8f4d3ea33d22155353137e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "376cbb73578d4743b95143487c767565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd2995919a2f4f1a8950e6019e36b261",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_201c0fead5e94a3ba8a6f07d9c91f2e7"
          }
        },
        "70631ea011104f8ebfaed5889f8ea6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86634840acae4d59a0718d9481025237",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 130B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d61c9644ab364b50a7d7b77f03520ca2"
          }
        },
        "bd2995919a2f4f1a8950e6019e36b261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "201c0fead5e94a3ba8a6f07d9c91f2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86634840acae4d59a0718d9481025237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d61c9644ab364b50a7d7b77f03520ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0230afda5a8147a6940e010177b8c922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a45d04325d0244188ca3a414c58ffe6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_603be56aa49c44f093652f786c83c257",
              "IPY_MODEL_72697ae3a68b4568a3df5ac82c678abe"
            ]
          }
        },
        "a45d04325d0244188ca3a414c58ffe6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "603be56aa49c44f093652f786c83c257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fd1c44b1f5f4fc88603ede0e003a4a8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1222317369,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1222317369,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c17fb0230af2470683890e18beb6fc84"
          }
        },
        "72697ae3a68b4568a3df5ac82c678abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6009ecb9e5c4103ba5b4e3752f6cbd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.22G/1.22G [01:18&lt;00:00, 15.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7262b1d8f3b42e387e1c6be10c13fff"
          }
        },
        "1fd1c44b1f5f4fc88603ede0e003a4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c17fb0230af2470683890e18beb6fc84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6009ecb9e5c4103ba5b4e3752f6cbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7262b1d8f3b42e387e1c6be10c13fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c367211a45942b2bde738031d18b7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aef5c050df294a73afbb10592e156160",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_195e3ef7a04e4df1891ce2ac5e31a998",
              "IPY_MODEL_43673f1b5d1647ad92d69f3eda3bef86"
            ]
          }
        },
        "aef5c050df294a73afbb10592e156160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "195e3ef7a04e4df1891ce2ac5e31a998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82f2fa1a750a49be9f29b3133b3c2cc2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f167219acab4dbea449ab7c90385d46"
          }
        },
        "43673f1b5d1647ad92d69f3eda3bef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01c8fe067aaf437aa6d03a526f3f28f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 1.52kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cecddb834f0645618dc713f7026ec2fd"
          }
        },
        "82f2fa1a750a49be9f29b3133b3c2cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f167219acab4dbea449ab7c90385d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01c8fe067aaf437aa6d03a526f3f28f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cecddb834f0645618dc713f7026ec2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5c3a81b143d42e9820a60733001cff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d715ced4dd814a50b2efa1341be2eec8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_521db42eca2f4ce1bd4b716d01784159",
              "IPY_MODEL_30d8bbff2d3b4360904f6b8109c8a307"
            ]
          }
        },
        "d715ced4dd814a50b2efa1341be2eec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "521db42eca2f4ce1bd4b716d01784159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49c8ddaf2c8742b592413b92155eabdb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd4b569b8bf64a3aa3720e579c516648"
          }
        },
        "30d8bbff2d3b4360904f6b8109c8a307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2663239ce4ca4a63bafd254c9aa2a46c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:20&lt;00:00, 64.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b24c51465b85469fa5c757ab8ad179ff"
          }
        },
        "49c8ddaf2c8742b592413b92155eabdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd4b569b8bf64a3aa3720e579c516648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2663239ce4ca4a63bafd254c9aa2a46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b24c51465b85469fa5c757ab8ad179ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e88a30ae16b48299d0f3d2c584d418f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab9fa8fde46947e8aa85a39a6e1687d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b19aac0b3164e509a930993ed8885db",
              "IPY_MODEL_d7234486e7a244f499ecc836fd8e61a4"
            ]
          }
        },
        "ab9fa8fde46947e8aa85a39a6e1687d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b19aac0b3164e509a930993ed8885db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7928f88233e64d17b917610c4dc42172",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9c938172923450fa43f8e3f104b47e4"
          }
        },
        "d7234486e7a244f499ecc836fd8e61a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41e5f3ca3d7e48f7b645107066e807b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 926kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14894c7ffd9447e1895466445332a6ae"
          }
        },
        "7928f88233e64d17b917610c4dc42172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9c938172923450fa43f8e3f104b47e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41e5f3ca3d7e48f7b645107066e807b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14894c7ffd9447e1895466445332a6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulowoicho/msc_project/blob/master/Summarization_Task_Results_and_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1cjCP-8pRz0",
        "colab_type": "text"
      },
      "source": [
        "#Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fozvY1K3uXVo",
        "colab_type": "text"
      },
      "source": [
        "Data is hosted on a google cloud bucket. Some processing was already done to convert the dataset from the original json format to a csv format with episode_id and transcript columns. Code for that is on github.\n",
        "\n",
        "The dataset contains over 100k different episodes. Episodes can be segmented by shows, with one show spanning several episodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toyGpaFpfdSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbd_s2aGiUme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e5e222e4-cc04-4d1c-d5d3-e20a004008c6"
      },
      "source": [
        "project_id = 'test-281700'\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n",
            "gs://spotify_asr_dataset/\n",
            "gs://staging.test-281700.appspot.com/\n",
            "gs://test-281700.appspot.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDS_jEC4mEou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19dc4005-b37c-4cbf-8ee9-d6ddad20e11e"
      },
      "source": [
        "bucket_name = 'spotify_asr_dataset'\n",
        "#download dataset\n",
        "!gsutil -m cp -r gs://{bucket_name}/dataset.csv /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://spotify_asr_dataset/dataset.csv...\n",
            "/ [1/1 files][  2.9 GiB/  2.9 GiB] 100% Done  27.7 MiB/s ETA 00:00:00           \n",
            "Operation completed over 1 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SojNkwZiovVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpUxwhEtVIuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a3b9ad5-152e-4329-c099-1412390880e9"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:399kdfMnjw0KYANZU7CQJ0</td>\n",
              "      <td>It's the mother back a podcast. Well that was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:49wcMBeJfaaL6KFFdsWvac</td>\n",
              "      <td>If you haven't heard about anchor is the easi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spotify:episode:0JOymLFsRdeBVZbEA72ayj</td>\n",
              "      <td>Hello and welcome to the podcast the first ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spotify:episode:7sHyO8wLeEd1LuxfS8AIls</td>\n",
              "      <td>Hey, hey. Hey. Hey. Hey, this is your girl Je...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spotify:episode:1WosITIkpJemzZaPh8zAVb</td>\n",
              "      <td>This is the planetary potential podcast for t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id                                         transcript\n",
              "0  spotify:episode:399kdfMnjw0KYANZU7CQJ0   It's the mother back a podcast. Well that was...\n",
              "1  spotify:episode:49wcMBeJfaaL6KFFdsWvac   If you haven't heard about anchor is the easi...\n",
              "2  spotify:episode:0JOymLFsRdeBVZbEA72ayj   Hello and welcome to the podcast the first ev...\n",
              "3  spotify:episode:7sHyO8wLeEd1LuxfS8AIls   Hey, hey. Hey. Hey. Hey, this is your girl Je...\n",
              "4  spotify:episode:1WosITIkpJemzZaPh8zAVb   This is the planetary potential podcast for t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0ymDQyVU4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d03a533-78e2-46c6-c23e-71f38981282d"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105360"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lveORK7V0bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6b1202f4-4819-40f1-cf32-4e6334a8b824"
      },
      "source": [
        "#download gold summaries\n",
        "!gsutil -m cp -r gs://{bucket_name}/150gold.tsv /content/\n",
        "\n",
        "#download metadata for episodes\n",
        "!gsutil -m cp -r gs://{bucket_name}/metadata.tsv /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://spotify_asr_dataset/150gold.tsv...\n",
            "- [1/1 files][379.9 KiB/379.9 KiB] 100% Done                                    \n",
            "Operation completed over 1 objects/379.9 KiB.                                    \n",
            "Copying gs://spotify_asr_dataset/metadata.tsv...\n",
            "\\ [1/1 files][112.2 MiB/112.2 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/112.2 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hDt_T9NvbYP",
        "colab_type": "text"
      },
      "source": [
        "Spotify also provides a set of 150 episodes for which baseline models were used to generate summaries. These summaries are compared against the creator provided episode descriptions, which vary in quality per the evaluation of spotify's annotators using an EGFB grading scale. \n",
        "\n",
        "Metadata file contains other information about each episode which may or may not be useful for training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEaaWRztY017",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gold_summaries = pd.read_csv('150gold.tsv', sep='\\t')\n",
        "podcasts_metadata = pd.read_csv('metadata.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuFv1ntHZWRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "d1252645-44c1-4980-fb75-581dd9e9fdf6"
      },
      "source": [
        "gold_summaries.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show name</th>\n",
              "      <th>episode name</th>\n",
              "      <th>episode id</th>\n",
              "      <th>creator description</th>\n",
              "      <th>EGFB</th>\n",
              "      <th>lexrank summary</th>\n",
              "      <th>EGFB.1</th>\n",
              "      <th>textrank summary</th>\n",
              "      <th>EGFB.2</th>\n",
              "      <th>lsa summary</th>\n",
              "      <th>EGFB.3</th>\n",
              "      <th>quasi-supervised summary</th>\n",
              "      <th>EGFB.4</th>\n",
              "      <th>supervised summary</th>\n",
              "      <th>EGFB.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alpha Male Strategies</td>\n",
              "      <td>Passive Aggressive Women &amp; Developing Mental S...</td>\n",
              "      <td>spotify:episode:4KRC1TZ28FavN3J5zLHEtQ</td>\n",
              "      <td>Boost the podcast! Leave a 5-star review on th...</td>\n",
              "      <td>B</td>\n",
              "      <td>All right guys now as y'all guys might know so...</td>\n",
              "      <td>G</td>\n",
              "      <td>There's no such thing as talk about passengers...</td>\n",
              "      <td>F</td>\n",
              "      <td>I'll pay for all you guys who don't know what ...</td>\n",
              "      <td>F</td>\n",
              "      <td>All women a passive-aggressive. When a woman w...</td>\n",
              "      <td>G</td>\n",
              "      <td>Rejection is a woman’s way of saying you’re no...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I Hope the Day Has a Good YOU!</td>\n",
              "      <td>If You Are Bored, You Are Boring.</td>\n",
              "      <td>spotify:episode:4tdDQcsBOUVWnA9XrpgTzS</td>\n",
              "      <td>☀️ aGoodYOU.com 🧡 Discuss this episode in 🗣: f...</td>\n",
              "      <td>B</td>\n",
              "      <td>It was the first and last time I ever said tha...</td>\n",
              "      <td>E</td>\n",
              "      <td>The answer usually comes in the form of a whis...</td>\n",
              "      <td>E</td>\n",
              "      <td>It was the first and last time I ever said tha...</td>\n",
              "      <td>F</td>\n",
              "      <td>If you are bored you are boring. Most people m...</td>\n",
              "      <td>E</td>\n",
              "      <td>If you are bored, you are boring.  ---   Suppo...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>American English Grammar Review</td>\n",
              "      <td>Prepositions of Movement Review Two American E...</td>\n",
              "      <td>spotify:episode:626YAxomH0HZ6nCW9NLlGY</td>\n",
              "      <td>Prepositions of movement review two is the sec...</td>\n",
              "      <td>F</td>\n",
              "      <td>So off is again the opposite of on what about ...</td>\n",
              "      <td>B</td>\n",
              "      <td>So off is again the opposite of on what about ...</td>\n",
              "      <td>B</td>\n",
              "      <td>Let's start out with into and out of into is t...</td>\n",
              "      <td>B</td>\n",
              "      <td>Prepositions of movement in this lesson. Let's...</td>\n",
              "      <td>B</td>\n",
              "      <td>In, out, and off refer to services differently...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simmers Digest</td>\n",
              "      <td>Simmer's Digest ep. 1.0 : Introductions</td>\n",
              "      <td>spotify:episode:6AUFl7KQWN6pzGFEIEKFQu</td>\n",
              "      <td>Welcome one and all to the newest the first ev...</td>\n",
              "      <td>F</td>\n",
              "      <td>I hope you enjoy it and I am excited to get to...</td>\n",
              "      <td>F</td>\n",
              "      <td>My passion for The Sims 4 Grew From consuming ...</td>\n",
              "      <td>E</td>\n",
              "      <td>So sit back turn your volume up to 11 and let'...</td>\n",
              "      <td>B</td>\n",
              "      <td>Techobabble is the host of the simmers digest ...</td>\n",
              "      <td>F</td>\n",
              "      <td>Welcome to the very first episode of The Simme...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kitty's Pod</td>\n",
              "      <td>TXT Run Away Reaction</td>\n",
              "      <td>spotify:episode:6C4V9iKa9qygtvJCngPO93</td>\n",
              "      <td>TXT Run Away Reaction  ---   This episode is s...</td>\n",
              "      <td>B</td>\n",
              "      <td>And I will tell you that I am very thrilled an...</td>\n",
              "      <td>B</td>\n",
              "      <td>And I will tell you that I am very thrilled an...</td>\n",
              "      <td>B</td>\n",
              "      <td>But before we get into that, if you haven't he...</td>\n",
              "      <td>B</td>\n",
              "      <td>Anchor is the easiest way to make a podcast. T...</td>\n",
              "      <td>B</td>\n",
              "      <td>Listen to the song Runaway by txt   ---   This...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         show name  ... EGFB.5\n",
              "0            Alpha Male Strategies  ...      B\n",
              "1   I Hope the Day Has a Good YOU!  ...      B\n",
              "2  American English Grammar Review  ...      B\n",
              "3                   Simmers Digest  ...      B\n",
              "4                      Kitty's Pod  ...      B\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YK-hlOrFfF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "0a67b0e7-951c-4c8c-8d5e-c43d5daad4a8"
      },
      "source": [
        "podcasts_metadata.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show_uri</th>\n",
              "      <th>show_name</th>\n",
              "      <th>show_description</th>\n",
              "      <th>publisher</th>\n",
              "      <th>language</th>\n",
              "      <th>rss_link</th>\n",
              "      <th>episode_uri</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>duration</th>\n",
              "      <th>show_filename_prefix</th>\n",
              "      <th>episode_filename_prefix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>Kream in your Koffee</td>\n",
              "      <td>A 20-something blunt female takes on the world...</td>\n",
              "      <td>Katie Houle</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
              "      <td>spotify:episode:000A9sRBYdVh66csG2qEdj</td>\n",
              "      <td>1: It’s Christmas Time!</td>\n",
              "      <td>On the first ever episode of Kream in your Kof...</td>\n",
              "      <td>12.700133</td>\n",
              "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>000A9sRBYdVh66csG2qEdj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:show:15iWCbU7QoO23EndPEO6aN</td>\n",
              "      <td>Morning Cup Of Murder</td>\n",
              "      <td>Ever wonder what murder took place on today in...</td>\n",
              "      <td>Morning Cup Of Murder</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/b07181c/podcast/rss</td>\n",
              "      <td>spotify:episode:000HP8n3hNIfglT2wSI2cA</td>\n",
              "      <td>The Goleta Postal Facility shootings- January ...</td>\n",
              "      <td>See something, say something. It’s a mantra ma...</td>\n",
              "      <td>6.019383</td>\n",
              "      <td>show_15iWCbU7QoO23EndPEO6aN</td>\n",
              "      <td>000HP8n3hNIfglT2wSI2cA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spotify:show:6vZRgUFTYwbAA79UNCADr4</td>\n",
              "      <td>Inside The 18 : A Podcast for Goalkeepers by G...</td>\n",
              "      <td>Inside the 18 is your source for all things Go...</td>\n",
              "      <td>Inside the 18 GK Media</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/81a072c/podcast/rss</td>\n",
              "      <td>spotify:episode:001UfOruzkA3Bn1SPjcdfa</td>\n",
              "      <td>Ep.36 - Incorporating a Singular Goalkeeping C...</td>\n",
              "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
              "      <td>43.616333</td>\n",
              "      <td>show_6vZRgUFTYwbAA79UNCADr4</td>\n",
              "      <td>001UfOruzkA3Bn1SPjcdfa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spotify:show:5BvKEjaMSuvUsGROGi2S7s</td>\n",
              "      <td>Arrowhead Live!</td>\n",
              "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
              "      <td>Arrowhead Live!</td>\n",
              "      <td>['en-US']</td>\n",
              "      <td>https://anchor.fm/s/917dba4/podcast/rss</td>\n",
              "      <td>spotify:episode:001i89SvIQgDuuyC53hfBm</td>\n",
              "      <td>Episode 1: Arrowhead Live! Debut</td>\n",
              "      <td>Join us as we take a look at all current Chief...</td>\n",
              "      <td>58.189200</td>\n",
              "      <td>show_5BvKEjaMSuvUsGROGi2S7s</td>\n",
              "      <td>001i89SvIQgDuuyC53hfBm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spotify:show:7w3h3umpH74veEJcbE6xf4</td>\n",
              "      <td>FBoL</td>\n",
              "      <td>The comedy podcast about toxic characters, wri...</td>\n",
              "      <td>Emily Edwards</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://www.fuckboisoflit.com/episodes?format=rss</td>\n",
              "      <td>spotify:episode:0025RWNwe2lnp6HcnfzwzG</td>\n",
              "      <td>The Lion, The Witch, And The Wardrobe - Ashley...</td>\n",
              "      <td>The modern morality tail of how to stay good f...</td>\n",
              "      <td>51.782050</td>\n",
              "      <td>show_7w3h3umpH74veEJcbE6xf4</td>\n",
              "      <td>0025RWNwe2lnp6HcnfzwzG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              show_uri  ... episode_filename_prefix\n",
              "0  spotify:show:2NYtxEZyYelR6RMKmjfPLB  ...  000A9sRBYdVh66csG2qEdj\n",
              "1  spotify:show:15iWCbU7QoO23EndPEO6aN  ...  000HP8n3hNIfglT2wSI2cA\n",
              "2  spotify:show:6vZRgUFTYwbAA79UNCADr4  ...  001UfOruzkA3Bn1SPjcdfa\n",
              "3  spotify:show:5BvKEjaMSuvUsGROGi2S7s  ...  001i89SvIQgDuuyC53hfBm\n",
              "4  spotify:show:7w3h3umpH74veEJcbE6xf4  ...  0025RWNwe2lnp6HcnfzwzG\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXBMhAlMaeP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "b49a3941-2adf-46bf-e70d-a7787cea48a9"
      },
      "source": [
        "#one show can span multiple episodes\n",
        "podcasts_metadata[podcasts_metadata['show_uri'] == 'spotify:show:2NYtxEZyYelR6RMKmjfPLB']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show_uri</th>\n",
              "      <th>show_name</th>\n",
              "      <th>show_description</th>\n",
              "      <th>publisher</th>\n",
              "      <th>language</th>\n",
              "      <th>rss_link</th>\n",
              "      <th>episode_uri</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>duration</th>\n",
              "      <th>show_filename_prefix</th>\n",
              "      <th>episode_filename_prefix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>Kream in your Koffee</td>\n",
              "      <td>A 20-something blunt female takes on the world...</td>\n",
              "      <td>Katie Houle</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
              "      <td>spotify:episode:000A9sRBYdVh66csG2qEdj</td>\n",
              "      <td>1: It’s Christmas Time!</td>\n",
              "      <td>On the first ever episode of Kream in your Kof...</td>\n",
              "      <td>12.700133</td>\n",
              "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>000A9sRBYdVh66csG2qEdj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11957</th>\n",
              "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>Kream in your Koffee</td>\n",
              "      <td>A 20-something blunt female takes on the world...</td>\n",
              "      <td>Katie Houle</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
              "      <td>spotify:episode:0sTNg31EACSHfZlt41RHmS</td>\n",
              "      <td>2: Tan Hands Save Lives</td>\n",
              "      <td>The do’s &amp; don’ts of self-tanning. A weird con...</td>\n",
              "      <td>20.016367</td>\n",
              "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>0sTNg31EACSHfZlt41RHmS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46132</th>\n",
              "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>Kream in your Koffee</td>\n",
              "      <td>A 20-something blunt female takes on the world...</td>\n",
              "      <td>Katie Houle</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
              "      <td>spotify:episode:3Ny7dKZ1QHZwadslXJ8Umf</td>\n",
              "      <td>6: #BYOD (with Liz Pickles)</td>\n",
              "      <td>On this week’s episode the gorgeous Liz Pickle...</td>\n",
              "      <td>80.472617</td>\n",
              "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>3Ny7dKZ1QHZwadslXJ8Umf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  show_uri  ... episode_filename_prefix\n",
              "0      spotify:show:2NYtxEZyYelR6RMKmjfPLB  ...  000A9sRBYdVh66csG2qEdj\n",
              "11957  spotify:show:2NYtxEZyYelR6RMKmjfPLB  ...  0sTNg31EACSHfZlt41RHmS\n",
              "46132  spotify:show:2NYtxEZyYelR6RMKmjfPLB  ...  3Ny7dKZ1QHZwadslXJ8Umf\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_rfPdMb_wG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_dataset = pd.merge(left=podcasts_metadata, right=dataset, how='left', left_on='episode_uri', right_on='episode_id')\n",
        "del full_dataset['episode_uri']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iiBMu8LjVQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "bbe357e5-29fb-49d5-8b57-f412f2ae48e1"
      },
      "source": [
        "full_dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show_uri</th>\n",
              "      <th>show_name</th>\n",
              "      <th>show_description</th>\n",
              "      <th>publisher</th>\n",
              "      <th>language</th>\n",
              "      <th>rss_link</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>duration</th>\n",
              "      <th>show_filename_prefix</th>\n",
              "      <th>episode_filename_prefix</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>Kream in your Koffee</td>\n",
              "      <td>A 20-something blunt female takes on the world...</td>\n",
              "      <td>Katie Houle</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
              "      <td>1: It’s Christmas Time!</td>\n",
              "      <td>On the first ever episode of Kream in your Kof...</td>\n",
              "      <td>12.700133</td>\n",
              "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
              "      <td>000A9sRBYdVh66csG2qEdj</td>\n",
              "      <td>spotify:episode:000A9sRBYdVh66csG2qEdj</td>\n",
              "      <td>Hello. Hello. Hello everyone. This is Katie a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:show:15iWCbU7QoO23EndPEO6aN</td>\n",
              "      <td>Morning Cup Of Murder</td>\n",
              "      <td>Ever wonder what murder took place on today in...</td>\n",
              "      <td>Morning Cup Of Murder</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/b07181c/podcast/rss</td>\n",
              "      <td>The Goleta Postal Facility shootings- January ...</td>\n",
              "      <td>See something, say something. It’s a mantra ma...</td>\n",
              "      <td>6.019383</td>\n",
              "      <td>show_15iWCbU7QoO23EndPEO6aN</td>\n",
              "      <td>000HP8n3hNIfglT2wSI2cA</td>\n",
              "      <td>spotify:episode:000HP8n3hNIfglT2wSI2cA</td>\n",
              "      <td>There were two more murders 15 miles away arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spotify:show:6vZRgUFTYwbAA79UNCADr4</td>\n",
              "      <td>Inside The 18 : A Podcast for Goalkeepers by G...</td>\n",
              "      <td>Inside the 18 is your source for all things Go...</td>\n",
              "      <td>Inside the 18 GK Media</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://anchor.fm/s/81a072c/podcast/rss</td>\n",
              "      <td>Ep.36 - Incorporating a Singular Goalkeeping C...</td>\n",
              "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
              "      <td>43.616333</td>\n",
              "      <td>show_6vZRgUFTYwbAA79UNCADr4</td>\n",
              "      <td>001UfOruzkA3Bn1SPjcdfa</td>\n",
              "      <td>spotify:episode:001UfOruzkA3Bn1SPjcdfa</td>\n",
              "      <td>Welcome to inside the 18. Today's episode is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spotify:show:5BvKEjaMSuvUsGROGi2S7s</td>\n",
              "      <td>Arrowhead Live!</td>\n",
              "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
              "      <td>Arrowhead Live!</td>\n",
              "      <td>['en-US']</td>\n",
              "      <td>https://anchor.fm/s/917dba4/podcast/rss</td>\n",
              "      <td>Episode 1: Arrowhead Live! Debut</td>\n",
              "      <td>Join us as we take a look at all current Chief...</td>\n",
              "      <td>58.189200</td>\n",
              "      <td>show_5BvKEjaMSuvUsGROGi2S7s</td>\n",
              "      <td>001i89SvIQgDuuyC53hfBm</td>\n",
              "      <td>spotify:episode:001i89SvIQgDuuyC53hfBm</td>\n",
              "      <td>Hey cheese fans before we get started. I want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spotify:show:7w3h3umpH74veEJcbE6xf4</td>\n",
              "      <td>FBoL</td>\n",
              "      <td>The comedy podcast about toxic characters, wri...</td>\n",
              "      <td>Emily Edwards</td>\n",
              "      <td>['en']</td>\n",
              "      <td>https://www.fuckboisoflit.com/episodes?format=rss</td>\n",
              "      <td>The Lion, The Witch, And The Wardrobe - Ashley...</td>\n",
              "      <td>The modern morality tail of how to stay good f...</td>\n",
              "      <td>51.782050</td>\n",
              "      <td>show_7w3h3umpH74veEJcbE6xf4</td>\n",
              "      <td>0025RWNwe2lnp6HcnfzwzG</td>\n",
              "      <td>spotify:episode:0025RWNwe2lnp6HcnfzwzG</td>\n",
              "      <td>Sorry to interrupt the show, but I do have to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              show_uri  ...                                         transcript\n",
              "0  spotify:show:2NYtxEZyYelR6RMKmjfPLB  ...   Hello. Hello. Hello everyone. This is Katie a...\n",
              "1  spotify:show:15iWCbU7QoO23EndPEO6aN  ...   There were two more murders 15 miles away arr...\n",
              "2  spotify:show:6vZRgUFTYwbAA79UNCADr4  ...   Welcome to inside the 18. Today's episode is ...\n",
              "3  spotify:show:5BvKEjaMSuvUsGROGi2S7s  ...   Hey cheese fans before we get started. I want...\n",
              "4  spotify:show:7w3h3umpH74veEJcbE6xf4  ...   Sorry to interrupt the show, but I do have to...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itYxILiZla6V",
        "colab_type": "text"
      },
      "source": [
        "#Recreate Baselines (TextRank, LexRank, Lsa)\n",
        "\n",
        "Three of the extractive baselines used on the dataset are TextRank, LexRank, and Latent Semantic Analysis. These can be easily replicated using the python Sumy package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Edi6kIdjYfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "428c7986-d037-4f57-9b4b-de95496ef23b"
      },
      "source": [
        "one_fifty_gold_summaries = full_dataset.loc[full_dataset[\"episode_id\"].isin(gold_summaries['episode id'])]\n",
        "len(one_fifty_gold_summaries)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIJYEEypl4Qn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "64d87594-3870-4ae1-e8df-c01fca9d12bd"
      },
      "source": [
        "one_fifty_gold_summaries = one_fifty_gold_summaries[['episode_id', 'episode_name', 'episode_description', 'transcript']]\n",
        "one_fifty_gold_summaries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1926</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2692</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2704</th>\n",
              "      <td>spotify:episode:0CGkzBarXCoYA24w5buABS</td>\n",
              "      <td>Favorite parts!!!</td>\n",
              "      <td>We will share some of our favorite parts of Ha...</td>\n",
              "      <td>Hello everybody, welcome back to butter girls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>spotify:episode:0DKARHBAz6GNwwIBz9Y4Sk</td>\n",
              "      <td>Fear? I Don't Know Her!</td>\n",
              "      <td>Hey eaters!! To commemorate spooky season, thi...</td>\n",
              "      <td>Hey heaters, it's Daisy and Abby and we are t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>spotify:episode:0Fg2g7eNnVBUj9FmtN8uKd</td>\n",
              "      <td>Unschool -001 /Introduction</td>\n",
              "      <td>Introduction | Show Formalities | What to Expe...</td>\n",
              "      <td>Hey, what's up, this is Uncle Sharma from the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99028</th>\n",
              "      <td>spotify:episode:7JdHnC4Jm05d7gsvpt2iMN</td>\n",
              "      <td>Self Guided 30 Minute Meditation | Meditation ...</td>\n",
              "      <td>Learn to meditate by practicing your own medit...</td>\n",
              "      <td>Thank you for joining me for another piece pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99372</th>\n",
              "      <td>spotify:episode:7LBJuMprDt6nN8lWZhw1ZN</td>\n",
              "      <td>The Lady Lemur</td>\n",
              "      <td>This week, John &amp; Kat are joined by the Lady L...</td>\n",
              "      <td>Welcome to the Leaky nib a podcast about pens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100490</th>\n",
              "      <td>spotify:episode:7dEbuTgXCXjIufsfgyohnI</td>\n",
              "      <td>1. Pilot</td>\n",
              "      <td>Bruce Forsyth, Sherlock's hair and time travel...</td>\n",
              "      <td>I've got something very excited to tell you t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104281</th>\n",
              "      <td>spotify:episode:7uv6JrgV01fiecvCgxRMy8</td>\n",
              "      <td>Best Organic Dessert Recipes</td>\n",
              "      <td>Comfort Foods for Cold Nights</td>\n",
              "      <td>Ingredients bolognese sauce 1 large onion coa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105261</th>\n",
              "      <td>spotify:episode:7zd15Qptaa1rxz4QCbHotX</td>\n",
              "      <td>BREAKING EMERGENCY POD: TYLER BARISHAW LIKELY ...</td>\n",
              "      <td>BREAKING EMERGENCY POD: TYLER BARISHAW LIKELY ...</td>\n",
              "      <td>Welcome to the good life.  Welcome to the goo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    episode_id  ...                                         transcript\n",
              "1926    spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...   Hello everybody. What's going on in this Jess...\n",
              "2692    spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...   Ladies, have you been molested don't be a vic...\n",
              "2704    spotify:episode:0CGkzBarXCoYA24w5buABS  ...   Hello everybody, welcome back to butter girls...\n",
              "2943    spotify:episode:0DKARHBAz6GNwwIBz9Y4Sk  ...   Hey heaters, it's Daisy and Abby and we are t...\n",
              "3463    spotify:episode:0Fg2g7eNnVBUj9FmtN8uKd  ...   Hey, what's up, this is Uncle Sharma from the...\n",
              "...                                        ...  ...                                                ...\n",
              "99028   spotify:episode:7JdHnC4Jm05d7gsvpt2iMN  ...   Thank you for joining me for another piece pr...\n",
              "99372   spotify:episode:7LBJuMprDt6nN8lWZhw1ZN  ...   Welcome to the Leaky nib a podcast about pens...\n",
              "100490  spotify:episode:7dEbuTgXCXjIufsfgyohnI  ...   I've got something very excited to tell you t...\n",
              "104281  spotify:episode:7uv6JrgV01fiecvCgxRMy8  ...   Ingredients bolognese sauce 1 large onion coa...\n",
              "105261  spotify:episode:7zd15Qptaa1rxz4QCbHotX  ...   Welcome to the good life.  Welcome to the goo...\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnjX297Vpt7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "32496d4c-c370-4281-b5b4-d16f97b1edc3"
      },
      "source": [
        "!pip install sumy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sumy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/20/8abf92617ec80a2ebaec8dc1646a790fc9656a4a4377ddb9f0cc90bc9326/sumy-0.8.1-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from sumy) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from sumy) (3.2.5)\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/2d/bb6c9b381e6b6a432aa2ffa8f4afdb2204f1ff97cfcc0766a5b7683fec43/breadability-0.1.20.tar.gz\n",
            "Collecting pycountry>=18.2.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->sumy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->sumy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.6/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Building wheels for collected packages: breadability, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21684 sha256=f7496fa4e217bf72f27f42955b357119b96ab33e569aed04945c798207718d3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/4d/a1/510b12c5e65e0b2b3ce539b2af66da0fc57571e528924f4a52\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=aba1644d94fe4e6ddacf064e0545b31efd5ea1e45346c51eb22825070cbe3ebb\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "Successfully built breadability pycountry\n",
            "Installing collected packages: breadability, pycountry, sumy\n",
            "Successfully installed breadability-0.1.20 pycountry-20.7.3 sumy-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Z8Ft5dsBwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f6aac848-c0b2-4f91-9b93-0a38492752ea"
      },
      "source": [
        "!python sumy_example.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsps2PCvq6AB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "12cba654-8cf3-4a88-f4ce-2b0a430dba87"
      },
      "source": [
        "from sumy_example import summarize\n",
        "\n",
        "one_fifty_gold_summaries['textrank_summary'] = one_fifty_gold_summaries.apply(lambda row: summarize(row['transcript'], 'text_rank'), axis=1)\n",
        "one_fifty_gold_summaries['lexrank_summary'] = one_fifty_gold_summaries.apply(lambda row: summarize(row['transcript'], 'lex_rank'), axis=1)\n",
        "one_fifty_gold_summaries['lsa_summary'] = one_fifty_gold_summaries.apply(lambda row: summarize(row['transcript'], 'lsa'), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (40) is lower than number of sentences (157). LSA algorithm may not work properly.\n",
            "  warn(message % (words_count, sentences_count))\n",
            "/usr/local/lib/python3.6/dist-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1076) is lower than number of sentences (1149). LSA algorithm may not work properly.\n",
            "  warn(message % (words_count, sentences_count))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EttJqLagrPid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "73fa5d2b-24a3-4d91-bd31-593a6447ec8c"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[3]['textrank_summary']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Yeah, and it gives you opportunity to be that courageous person where if you weren't afraid of something you would never know that it was actually like something you could have done and then they talked kind of talk about the fight or flight response and it's the eye  Dia of fear keeps us safe in a lot of situations like you and I are both very aware of where we are at night and looking around to different people and making sure we're safe and that fear Keeps Us Alive everyday. Yeah before you can actually show forth, which is one of the hardest parts of overcoming fear because admitting fear to yourself is scary foot and I got anything for your own fear to um, yeah. \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JmzVKoRyCEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9311cb0d-903a-48aa-e33d-1cec0ff7a467"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[3]['lexrank_summary']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I kind of get that fear also a side note of what I'm afraid of kidnap being kidnapped is probably the biggest one but in a much more real sense, it's going like I'm not accomplishing enough for giving enough that really ties in with the time thing because it says it yeah, we should be having something done. And what's my fear? \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSk5Qjo64-Jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "92151f73-4739-4fae-cc22-779f3fa6c323"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[3]['lsa_summary']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Yeah, so the idea of habituation  In the psychology today article talks about how it's when our nervous system returns to a more comfortable state, which is a good thing. When you happen to be in a very dangerous situation, once you return to this state of habituation, then you know that your body has calmed down but then we don't go outside and explore to a mode and we can go on autopilot and then then we're not as aware that we're doing it because we're just naturally doing it. \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EeShx8xBuWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_fifty_gold_summaries.iloc[3]['episode_description']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxkjLGXsvv7m",
        "colab_type": "text"
      },
      "source": [
        "#Recreate Baselines (Semi-Supervised Bart + Supervised Bart)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlZQMwhMxVwN",
        "colab_type": "text"
      },
      "source": [
        "Abstractive baselines used on the data are a semi-supervised bart, which is a bart model that was only pre-trained on the CNN/DailyMail dataset, and a supervised bart which is further fine-tuned on the spotify dataset. Due to compute constraints, the bart model is only fine-tuned on 5000 samples, although I will fine-tune on more samples and see if that improves the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86nhR65H9qGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "60ef807c-fb97-4ae9-94b5-c18c5b483671"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 14.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=eb7969afe106cd501abaf47448f78e08bf7bec0d9db6b5eba56e5481878e801d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75pkUDcQ_4tl",
        "colab_type": "text"
      },
      "source": [
        "##semi supervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U3GMDEByFQP",
        "colab_type": "text"
      },
      "source": [
        "Inference with the model consumes too much RAM on very long pieces of text, so I limit the length of text to the first 4000 characters. This is sure to impact results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2ziikql9rCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "a2ee0c9dc049495a9cfa7a4c87e43148",
            "bb9bb42dbb4145b997010d6b65816197",
            "07c3888e35a94209b310bf7c8652879e",
            "9c2b826873ac49fd94693c5341b74754",
            "25fd689c97144c0db80928b007a118ac",
            "dfdb8acea64e465d98a4f8333532da85",
            "85051cd8681c42bfb9410c94423d2808",
            "79f0680581914aa9a69d08a12a5719ee",
            "fec84906f0134e8aa9ff603612229dd3",
            "65c1710660f244e1833dc80841074f15",
            "1a7c4de3325f4904843b80405883177a",
            "e0b6fdb9eed441ba8122db95aae7b64b",
            "0973e28442994c84973567ee8fe39306",
            "e7c871bbfc4245b8afa54afa22bfa60c",
            "7db9f49dc74649eebe6431165f0dc7e3",
            "3d3e2aae4bc0493b9a0b2365a7bfe85d",
            "72e04089282c48fb9dff5382cdbb8ad0",
            "6c7d3a82e22c42e183ac13171d1e49f8",
            "ef4f5ff6846845c8950732a27d8ec255",
            "3ca4f4edd23f47feb8e789083aef93f5",
            "d18b6608126447b1b12efa20267617ec",
            "59021576d2aa40f9bf3ebe49b69463d4",
            "077f6570fd3e4aeeb7c471f4b31b44f4",
            "2908490d95bf4e9dae82e978d01224af",
            "a6ef7faa74c94b8d951ff5d60308c23f",
            "626591f60e8f4d3ea33d22155353137e",
            "376cbb73578d4743b95143487c767565",
            "70631ea011104f8ebfaed5889f8ea6ca",
            "bd2995919a2f4f1a8950e6019e36b261",
            "201c0fead5e94a3ba8a6f07d9c91f2e7",
            "86634840acae4d59a0718d9481025237",
            "d61c9644ab364b50a7d7b77f03520ca2",
            "0230afda5a8147a6940e010177b8c922",
            "a45d04325d0244188ca3a414c58ffe6c",
            "603be56aa49c44f093652f786c83c257",
            "72697ae3a68b4568a3df5ac82c678abe",
            "1fd1c44b1f5f4fc88603ede0e003a4a8",
            "c17fb0230af2470683890e18beb6fc84",
            "a6009ecb9e5c4103ba5b4e3752f6cbd1",
            "c7262b1d8f3b42e387e1c6be10c13fff"
          ]
        },
        "outputId": "aa35caa9-4b94-4c4e-d04e-b2196a496f58"
      },
      "source": [
        "from transformers import pipeline\n",
        "bart_summarizer = pipeline(\"summarization\")\n",
        "\n",
        "\n",
        "def semi_supervised_bart(transcript):\n",
        "  summary = bart_summarizer(transcript[:4000], min_length=50, max_length=150)\n",
        "  return summary[0]['summary_text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2ee0c9dc049495a9cfa7a4c87e43148",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1578.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fec84906f0134e8aa9ff603612229dd3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e04089282c48fb9dff5382cdbb8ad0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6ef7faa74c94b8d951ff5d60308c23f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0230afda5a8147a6940e010177b8c922",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1222317369.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7GZ8syl-yaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "494550be-edef-4b2d-d438-3bcdf34fc5b7"
      },
      "source": [
        "one_fifty_gold_summaries['semi_supervised'] = one_fifty_gold_summaries.apply(lambda row: semi_supervised_bart(row['transcript']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
            "Your max_length is set to 150, but you input_length is only 142. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
            "Your max_length is set to 150, but you input_length is only 142. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK0OUTc2_DT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7eebdea1-2df7-448b-9157-4365b3f75c7a"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[3]['semi_supervised']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Daisy and Abby talk about fear and how courage and fear go hand in hand . Abby says fear is not a sign of what you shouldn't do, it's a call to action . Abby: I have this weird fear that I'm not doing enough at the moment and that I kind of compare myself to other people and I'm like, well this person is doing this and I could be doing a lot more .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAVDt4sSMJ02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6a9dfa69-217a-41f2-f4aa-3c6be556e964"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[1]['semi_supervised']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" If you have been molested call the police shout for help and call nine nine nine . Don't be a silent victim avoid walking through secluded areas alone . Have someone escort you home when it's late above all try your best not to be molested by a culprit from a good University who has good academic results and the potential to excel in life .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEO3Qxtx_-qD",
        "colab_type": "text"
      },
      "source": [
        "##supervised (trained on 5000 transcripts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_JFPbpPAFCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e4d18cc-d3d0-4f31-d7eb-bebb4f6232e1"
      },
      "source": [
        "!pip install ohmeow-blurr\n",
        "!pip install nlp\n",
        "!pip install pyarrow==0.16.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ohmeow-blurr\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/80/6dfb38121c4d61d3f8d72d16ff45b23e6a1ef0ac798a1e2b03542e8e0500/ohmeow_blurr-0.0.7-py3-none-any.whl\n",
            "Collecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/77/9b8a06120e85d8057339a87dca967c8b73280fe463702cc4966c30f43960/nlp-0.3.0-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.8MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (3.0.2)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Collecting fastcore\n",
            "  Downloading https://files.pythonhosted.org/packages/47/54/84e9f7c5ab718526e891fef0801e3cab98b4e4e28471fbd0e41efbbbe412/fastcore-0.1.20-py3-none-any.whl\n",
            "Collecting fastai2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/43/2bc6f2fbbd01356de1903d9e8a05a7d65a6e323f62d86a448a0f1a28077e/fastai2-0.0.21-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (4.10.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (0.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (3.0.12)\n",
            "Collecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/0a/a89de6d747c4698af128a46398703e3d1889f196478fd94a4e16bd1b5c65/pyarrow-1.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.2MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2MB 221kB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->ohmeow-blurr) (2.3.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.8.1rc1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (20.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.1.91)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (0.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.4.1)\n",
            "Collecting torchvision>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.0.5)\n",
            "Collecting fastprogress>=0.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/26/6db6f8f976379c04af888bb5d45af64e8b69c5bfb2672a427da2dde89441/fastprogress-0.2.4-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.22.2.post1)\n",
            "Collecting torch>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (7.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (4.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (2020.6.20)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (1.0.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->ohmeow-blurr) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->ohmeow-blurr) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->ohmeow-blurr) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (2.8.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (49.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->ohmeow-blurr) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai2->ohmeow-blurr) (0.16.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (4.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (19.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->ohmeow-blurr) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (1.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=46a1e78d15e337bd921ae319e0f4b0258563fba7ca5aacd394d9183de2eb3d05\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: pyarrow, nlp, seqeval, rouge-score, fastcore, torch, torchvision, fastprogress, fastai2, ohmeow-blurr\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "  Found existing installation: fastprogress 0.2.3\n",
            "    Uninstalling fastprogress-0.2.3:\n",
            "      Successfully uninstalled fastprogress-0.2.3\n",
            "Successfully installed fastai2-0.0.21 fastcore-0.1.20 fastprogress-0.2.4 nlp-0.3.0 ohmeow-blurr-0.0.7 pyarrow-1.0.0 rouge-score-0.0.4 seqeval-0.0.12 torch-1.6.0 torchvision-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow",
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Collecting pyarrow==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1MB)\n",
            "\u001b[K     |████████████████████████████████| 63.2MB 162kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.18.5)\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 1.0.0\n",
            "    Uninstalling pyarrow-1.0.0:\n",
            "      Successfully uninstalled pyarrow-1.0.0\n",
            "Successfully installed pyarrow-0.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://spotify_asr_dataset/BART_finetuned_5000.pkl...\n",
            "- [1/1 files][  1.8 GiB/  1.8 GiB] 100% Done  53.4 MiB/s ETA 00:00:00           \n",
            "Operation completed over 1 objects/1.8 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaGIecufCZSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_fifty_gold_summaries.to_csv('150_gold.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7qHdy3DNlx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "0b57dbef-20a8-4df5-9f9e-beff595d712e"
      },
      "source": [
        "#restarted run time\n",
        "import pandas as pd\n",
        "one_fifty_gold_summaries = pd.read_csv('150_gold.csv')\n",
        "one_fifty_gold_summaries.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>textrank_summary</th>\n",
              "      <th>lexrank_summary</th>\n",
              "      <th>lsa_summary</th>\n",
              "      <th>semi_supervised</th>\n",
              "      <th>supervised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>Let's download these stories about whoever I d...</td>\n",
              "      <td>You can do whatever networking events and I'm ...</td>\n",
              "      <td>We're going to talk about some powerful recrui...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peop...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>Have someone escort you home when it's late ab...</td>\n",
              "      <td>But you can touch his life. But you can touch ...</td>\n",
              "      <td>If you only touched you in minor ways never mi...</td>\n",
              "      <td>If you have been molested call the police sho...</td>\n",
              "      <td>Ladies, have you been molested don't be a vict...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id  ...                                         supervised\n",
              "0  spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...  You cannot scummy hashtag wisely, or the peopl...\n",
              "1  spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...  Ladies, have you been molested don't be a vict...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YQhq4l5Ahre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlp\n",
        "from fastai2.text.all import *\n",
        "from transformers import *\n",
        "\n",
        "from blurr.data.all import *\n",
        "from blurr.modeling.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EerUWkMAfDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "22e73fa8-2edc-4463-95f7-d3c75c6dcfc9"
      },
      "source": [
        "supervised_bart_model = load_learner(fname='BART_finetuned_5000.pkl')\n",
        "\n",
        "def supervised_bart(transcript):\n",
        "  return supervised_bart_model.generate_text(transcript)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwWSMbeHO2vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_fifty_gold_summaries['supervised'] = one_fifty_gold_summaries.apply(lambda row: supervised_bart(row['transcript']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I9ETwlaNTnwN",
        "colab": {}
      },
      "source": [
        "one_fifty_gold_summaries.to_csv('150_gold.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8YcjqBn7PYc",
        "colab_type": "text"
      },
      "source": [
        "#Recreate Baselines (First Five Sentences/first min?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqBDejmxzuWQ",
        "colab_type": "text"
      },
      "source": [
        "With the way I reformatted the data, implementing a baseline that looks at the words uttered in the first minute of the podcast might be ineffective as it would involve lots of assumptions. For example, the average speaker says 125 words per minute, taking the first 125 words as my summary would not take into account speakers who pause alot while talking. \n",
        "\n",
        "The original dataset contains the timestamp which each word was uttered, I could have hosted the files somewhere and looked up the associated transcript via an API as needed, but the set of uncompressed files is very large.\n",
        "\n",
        "I decided to go with the first five sentences with the assumption that it could be fairly representative of the first minute of a podcast and that it is fairly trivial to implement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iND9eJ4lasXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "ac5a5e6b-773a-4942-b4e2-b61a8094b3e3"
      },
      "source": [
        "import pandas as pd\n",
        "results = pd.read_csv('150_gold.csv') #or download from bucket\n",
        "results.head(2)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>textrank_summary</th>\n",
              "      <th>lexrank_summary</th>\n",
              "      <th>lsa_summary</th>\n",
              "      <th>semi_supervised</th>\n",
              "      <th>supervised</th>\n",
              "      <th>extractive</th>\n",
              "      <th>t5_abstractive</th>\n",
              "      <th>first_five</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>Let's download these stories about whoever I d...</td>\n",
              "      <td>You can do whatever networking events and I'm ...</td>\n",
              "      <td>We're going to talk about some powerful recrui...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peop...</td>\n",
              "      <td>In this episode I talk about some powerful re...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peopl...</td>\n",
              "      <td>--- This episode is sponsored by  Anchor: The ...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>Have someone escort you home when it's late ab...</td>\n",
              "      <td>But you can touch his life. But you can touch ...</td>\n",
              "      <td>If you only touched you in minor ways never mi...</td>\n",
              "      <td>If you have been molested call the police sho...</td>\n",
              "      <td>If you have been molested, here are some of t...</td>\n",
              "      <td>Ladies, have you been molested don't be a vict...</td>\n",
              "      <td>Ladies, have you been molested? Don't be a sil...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id  ...                                         first_five\n",
              "0  spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...   Hello everybody. What's going on in this Jess...\n",
              "1  spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...   Ladies, have you been molested don't be a vic...\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMdYXgVPbAJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c52c613d-491b-48bd-baf2-81d794452a0f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def first_five(transcript, threshold):\n",
        "  sentences = sent_tokenize(transcript)\n",
        "  return ' '.join(sentences[:threshold])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJbmh0XTfQle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results['first_five'] = results.apply(lambda row: first_five(row['transcript'], 5), axis=1)\n",
        "results.to_csv('150_gold.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpUoy621gEw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2d8d1232-1e12-4de2-dd40-40c2185f3102"
      },
      "source": [
        "results.iloc[0]['first_five']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Hello everybody. What's going on in this Jesse Lee? You cannot scummy hashtag wisely, or the people's Mentor in today. We're going to talk about some powerful recruiting techniques for massive growth in your business and in your team, and so if you are new to this program, feel free to subscribe share with a friend do all the good things. I appreciate you guys.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKmk5Xu-Da9w",
        "colab_type": "text"
      },
      "source": [
        "#Extractive (BERT + KMeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgDa7HZZysTk",
        "colab_type": "text"
      },
      "source": [
        "The Bert + Kmeans approach is based on the bert-extractive-summarizer project by dmiller where bert is used to encode sentences and kmeans is used to create a clustering of the encodings. Sentences that make the final summary are those closest to the clusters generated. The default number of clusters is two, and I stick with that. However, I wonder how results would be affected if the number of clusters was changed. Also, the model is not fine-tuned. What would happen if it was?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4BNDzDATwWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "5725e142-b1d8-4abf-8262-89c1ddd66f5d"
      },
      "source": [
        "#restarted run time\n",
        "import pandas as pd\n",
        "one_fifty_gold_summaries = pd.read_csv('150_gold.csv')\n",
        "one_fifty_gold_summaries.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>textrank_summary</th>\n",
              "      <th>lexrank_summary</th>\n",
              "      <th>lsa_summary</th>\n",
              "      <th>semi_supervised</th>\n",
              "      <th>supervised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>Let's download these stories about whoever I d...</td>\n",
              "      <td>You can do whatever networking events and I'm ...</td>\n",
              "      <td>We're going to talk about some powerful recrui...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peop...</td>\n",
              "      <td>In this episode I talk about some powerful re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>Have someone escort you home when it's late ab...</td>\n",
              "      <td>But you can touch his life. But you can touch ...</td>\n",
              "      <td>If you only touched you in minor ways never mi...</td>\n",
              "      <td>If you have been molested call the police sho...</td>\n",
              "      <td>If you have been molested, here are some of t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id  ...                                         supervised\n",
              "0  spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...   In this episode I talk about some powerful re...\n",
              "1  spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...   If you have been molested, here are some of t...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U889yfpJ652",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "335cde71-ad93-43e9-dc27-6f6d35c08db3"
      },
      "source": [
        "!git clone https://github.com/paulowoicho/bert-extractive-summarizer.git\n",
        "!pip install spacy\n",
        "!pip install neuralcoref\n",
        "!mv bert-extractive-summarizer summarizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert-extractive-summarizer'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 3 (delta 0), pack-reused 374\u001b[K\n",
            "Receiving objects: 100% (378/378), 85.48 KiB | 735.00 KiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Collecting neuralcoref\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/24/0ec7845a5b73b637aa691ff4d1b9b48f3a0f3369f4002a59ffd7a7462fdb/neuralcoref-4.0-cp36-cp36m-manylinux1_x86_64.whl (287kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.14.24)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.2.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.17.24)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (49.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->neuralcoref) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->neuralcoref) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (1.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.24->boto3->neuralcoref) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.1.0)\n",
            "Installing collected packages: neuralcoref\n",
            "Successfully installed neuralcoref-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skCPpWfCKX8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e0e87f10-8d66-4c9f-b478-495d24dd03f4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrEOWpzjcGUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "553ef9df-f539-4cb7-d893-ba25d7744773"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2c5b88f9b9f364db0811ce53e780d10b86fc925cfb41b75ff393d758553aa91c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CX55PmQKdmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "3c367211a45942b2bde738031d18b7b6",
            "aef5c050df294a73afbb10592e156160",
            "195e3ef7a04e4df1891ce2ac5e31a998",
            "43673f1b5d1647ad92d69f3eda3bef86",
            "82f2fa1a750a49be9f29b3133b3c2cc2",
            "7f167219acab4dbea449ab7c90385d46",
            "01c8fe067aaf437aa6d03a526f3f28f3",
            "cecddb834f0645618dc713f7026ec2fd",
            "f5c3a81b143d42e9820a60733001cff3",
            "d715ced4dd814a50b2efa1341be2eec8",
            "521db42eca2f4ce1bd4b716d01784159",
            "30d8bbff2d3b4360904f6b8109c8a307",
            "49c8ddaf2c8742b592413b92155eabdb",
            "fd4b569b8bf64a3aa3720e579c516648",
            "2663239ce4ca4a63bafd254c9aa2a46c",
            "b24c51465b85469fa5c757ab8ad179ff",
            "3e88a30ae16b48299d0f3d2c584d418f",
            "ab9fa8fde46947e8aa85a39a6e1687d3",
            "6b19aac0b3164e509a930993ed8885db",
            "d7234486e7a244f499ecc836fd8e61a4",
            "7928f88233e64d17b917610c4dc42172",
            "b9c938172923450fa43f8e3f104b47e4",
            "41e5f3ca3d7e48f7b645107066e807b7",
            "14894c7ffd9447e1895466445332a6ae"
          ]
        },
        "outputId": "e795d7e5-90b8-4ca3-c262-116543ac6091"
      },
      "source": [
        "from summarizer import Summarizer\n",
        "extractive_model = Summarizer()\n",
        "\n",
        "def extractive_summary(transcript):\n",
        "  result = extractive_model(transcript, min_length=60, ratio=0.01)\n",
        "  return ''.join(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c367211a45942b2bde738031d18b7b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c3a81b143d42e9820a60733001cff3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e88a30ae16b48299d0f3d2c584d418f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNT5g0zgpBZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_fifty_gold_summaries['extractive'] = one_fifty_gold_summaries.apply(lambda row: extractive_summary(row['transcript']), axis=1)\n",
        "one_fifty_gold_summaries.to_csv('150_gold.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOgUaf7NfbwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "e45cf81a-6087-4e68-c7e2-8916d68dafa4"
      },
      "source": [
        "one_fifty_gold_summaries.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>textrank_summary</th>\n",
              "      <th>lexrank_summary</th>\n",
              "      <th>lsa_summary</th>\n",
              "      <th>semi_supervised</th>\n",
              "      <th>supervised</th>\n",
              "      <th>extractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>Let's download these stories about whoever I d...</td>\n",
              "      <td>You can do whatever networking events and I'm ...</td>\n",
              "      <td>We're going to talk about some powerful recrui...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peop...</td>\n",
              "      <td>In this episode I talk about some powerful re...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>Have someone escort you home when it's late ab...</td>\n",
              "      <td>But you can touch his life. But you can touch ...</td>\n",
              "      <td>If you only touched you in minor ways never mi...</td>\n",
              "      <td>If you have been molested call the police sho...</td>\n",
              "      <td>If you have been molested, here are some of t...</td>\n",
              "      <td>Ladies, have you been molested don't be a vict...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id  ...                                         extractive\n",
              "0  spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...  You cannot scummy hashtag wisely, or the peopl...\n",
              "1  spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...  Ladies, have you been molested don't be a vict...\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vLnEj9nfydK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "899f6354-6163-4802-cc98-a336f1ec3397"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[7]['extractive']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"If you ever heard about anchor it's the easiest way to make a podcast. They make 90 degree turns and they're following people and they like all suddenly like six eliminations in a row and while when I say, they're doing 90 degree rotations, that's also while building structures and going through walls and editing its it was really an interesting to watch the perfect gives you ideas of how to play better. I like he got a lot of them will eliminations but he doesn't get credit for them because he didn't actually hit them with a bullet.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlGP45gDh5Q",
        "colab_type": "text"
      },
      "source": [
        "#Abstractive (T5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cny7a9F_zgYI",
        "colab_type": "text"
      },
      "source": [
        "The t5 model is only fine-tuned on 3000 samples due to compute constraints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux-JqBz67Dfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ed047b7b-e391-43da-9f1f-fb56637188c6"
      },
      "source": [
        "#set up again because restarted runtime\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "project_id = 'test-281700'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "#download model..restarted runtime\n",
        "bucket_name = 'spotify_asr_dataset'\n",
        "!gsutil -m cp -r gs://{bucket_name}/t5-model-3000.zip /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n",
            "Copying gs://spotify_asr_dataset/t5-model-3000.zip...\n",
            "- [1/1 files][787.9 MiB/787.9 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/787.9 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCS6AomVNWGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "2dbe46d1-088d-4edd-c09b-4b3e9ca8c4ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 5.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2247e9c35a7710a658bfa6018fda527bf65d97f95d06d7b2fa614d83e8619cff\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71wVz_F7j5bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6c071e4e-226a-4dbc-9994-4a26e5334514"
      },
      "source": [
        "!unzip t5-model-3000.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  t5-model-3000.zip\n",
            "   creating: t5-model-3000/\n",
            "  inflating: t5-model-3000/pytorch_model.bin  \n",
            " extracting: t5-model-3000/tokenizer_config.json  \n",
            "  inflating: t5-model-3000/config.json  \n",
            "  inflating: t5-model-3000/spiece.model  \n",
            "  inflating: t5-model-3000/special_tokens_map.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8fPl6LvYWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "86d25b09-0a1c-4544-b433-75f2677c6ca7"
      },
      "source": [
        "import pandas as pd\n",
        "one_fifty_gold_summaries = pd.read_csv('150_gold.csv')\n",
        "one_fifty_gold_summaries.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode_id</th>\n",
              "      <th>episode_name</th>\n",
              "      <th>episode_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>textrank_summary</th>\n",
              "      <th>lexrank_summary</th>\n",
              "      <th>lsa_summary</th>\n",
              "      <th>semi_supervised</th>\n",
              "      <th>supervised</th>\n",
              "      <th>extractive</th>\n",
              "      <th>t5_abstractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotify:episode:08hXUWN6aOnHULXrqMiwTi</td>\n",
              "      <td>Recruiting Secrets From a MLM Recruiting Monst...</td>\n",
              "      <td>If you want to start mastering recruiting whic...</td>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>Let's download these stories about whoever I d...</td>\n",
              "      <td>You can do whatever networking events and I'm ...</td>\n",
              "      <td>We're going to talk about some powerful recrui...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peop...</td>\n",
              "      <td>In this episode I talk about some powerful re...</td>\n",
              "      <td>You cannot scummy hashtag wisely, or the peopl...</td>\n",
              "      <td>--- This episode is sponsored by  Anchor: The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotify:episode:0CExTNH4LFqp1ec1mhTd4I</td>\n",
              "      <td>A Public Service Announcement from the mrbrown...</td>\n",
              "      <td>Don't be a silent victim of crime. a parody fr...</td>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>Have someone escort you home when it's late ab...</td>\n",
              "      <td>But you can touch his life. But you can touch ...</td>\n",
              "      <td>If you only touched you in minor ways never mi...</td>\n",
              "      <td>If you have been molested call the police sho...</td>\n",
              "      <td>If you have been molested, here are some of t...</td>\n",
              "      <td>Ladies, have you been molested don't be a vict...</td>\n",
              "      <td>Ladies, have you been molested? Don't be a sil...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               episode_id  ...                                     t5_abstractive\n",
              "0  spotify:episode:08hXUWN6aOnHULXrqMiwTi  ...  --- This episode is sponsored by  Anchor: The ...\n",
              "1  spotify:episode:0CExTNH4LFqp1ec1mhTd4I  ...  Ladies, have you been molested? Don't be a sil...\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w64g4JffeSw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76cf66ff-47ed-4cb3-f60f-81b0da021ef1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pngw_L2tnVuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# # # Setting up the device for GPU usage\n",
        "# from torch import cuda\n",
        "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('/content/t5-model-3000')\n",
        "model = T5ForConditionalGeneration.from_pretrained('/content/t5-model-3000')\n",
        "\n",
        "\n",
        "def t5_inference(transcript):\n",
        "  threshold = 7000\n",
        "  t5_form = 'summarize: ' + transcript\n",
        "  tokenized_text = tokenizer.encode(t5_form, return_tensors=\"pt\")\n",
        "  if len(tokenized_text[0]) > threshold:\n",
        "    #run out of RAM/crashes on large number of tokens\n",
        "    revised_text = sent_tokenize(t5_form)\n",
        "    length = len(revised_text)\n",
        "    final_text = revised_text[:int(length/2)] #maybe they talk about content in the first half? find proof\n",
        "    text = ' '.join(final_text)\n",
        "    return t5_inference(text)\n",
        "  summary_ids = model.generate(tokenized_text, max_length=150, num_beams=2, repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
        "  output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-kEWKOrpzFh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27c6dbea-e472-4ad8-f5e1-779df93f2fc3"
      },
      "source": [
        "one_fifty_gold_summaries['t5_abstractive'] = one_fifty_gold_summaries.apply(lambda row: t5_inference(row['transcript']), axis=1)\n",
        "one_fifty_gold_summaries.to_csv('150_gold.csv', index=False)\n",
        "!gsutil -m cp -r /content/150_gold.csv gs://{bucket_name}/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5474 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2458 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12221 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5394 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3708 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5445 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12170 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6442 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (18276 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10235 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4445 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12262 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4291 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6401 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6490 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4981 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7887 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4175 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3917 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2033 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9190 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4345 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3493 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8813 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3823 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3773 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12403 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5450 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2845 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7383 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8196 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4479 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (14322 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6158 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4252 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15869 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7361 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3138 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12014 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6021 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6448 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13951 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6864 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10659 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5335 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3262 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7100 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7020 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3898 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3263 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (14674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6462 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5432 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4740 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10340 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9141 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6231 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10356 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5004 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2887 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (11423 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6167 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2240 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8295 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (23456 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4498 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8233 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4180 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9335 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4833 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (14419 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7145 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4075 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3134 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (11463 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6010 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8280 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3406 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17253 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8804 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4186 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (11645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (21969 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10427 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4280 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12366 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7302 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3210 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3123 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9477 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (18065 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8757 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4442 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2233 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3376 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8267 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3776 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5378 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10172 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5237 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (16943 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8329 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4137 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3468 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7371 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (14824 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6946 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5887 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6146 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6340 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (19274 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (11177 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5375 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4070 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (18085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8881 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15234 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5427 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13353 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4316 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5660 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3624 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/150_gold.csv [Content-Type=text/csv]...\n",
            "/ [0/1 files][    0.0 B/  4.3 MiB]   0% Done                                    \r/ [1/1 files][  4.3 MiB/  4.3 MiB] 100% Done                                    \r-\r\n",
            "Operation completed over 1 objects/4.3 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHrhMtkCv8Hz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9345febc-eb57-4f35-99c5-b5c4288ec450"
      },
      "source": [
        "one_fifty_gold_summaries.iloc[5]['t5_abstractive']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I talk about anger and how we deal with it. --- Send in a voice message: https://anchor.fm/thebeast-podcast/message Support this podcast: https://anchor.fm/thebeast-podcast/support this podcast: https://anchor.fm/thebeast-podcast/support this podcast: https://anchor.fm/thebeast-podcast/support this podcast: https://anchor.fm/thebeast-podcast/support this podcast: https://anchor.fm/thebeast/support this podcast: https://anchor.fm/thebeast-podcast'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieS6tf87_HaM",
        "colab_type": "text"
      },
      "source": [
        "#Extractive + Abstractive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEFHFdMp_Vc-",
        "colab_type": "text"
      },
      "source": [
        "Given the performance of the abstractive and extractive models, I would like to see how well a combination of both performs. My best extractive models are First Five Sentences and Bert + KMeans. On their own, I doubt that their results would provide enough context to serve as meaningful input to an extractive model, so I can expand first five sentences to include the first 15, and increase the threshold for bert + kmeans to include more important sentences (It is currently 1% of total sentences, maybe 10%?)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrO6oRX4Kb7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "0c657c52-953b-4e5d-cb3c-1bf9af9af982"
      },
      "source": [
        "#first_15\n",
        "extractive_results = pd.DataFrame(columns=['first_15', 'bert_kmeans'])\n",
        "extractive_results['first_15'] = results.apply(lambda row: first_five(row['transcript'], 15), axis=1)\n",
        "\n",
        "extractive_results.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_15</th>\n",
              "      <th>bert_kmeans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello everybody. What's going on in this Jess...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ladies, have you been molested don't be a vic...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            first_15 bert_kmeans\n",
              "0   Hello everybody. What's going on in this Jess...         NaN\n",
              "1   Ladies, have you been molested don't be a vic...         NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ngVEKeMhpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "19e2ef40-c673-419c-affc-dafe79aa9aca"
      },
      "source": [
        "#bert + kmeans (10%)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Hello everybody. What's going on in this Jesse Lee? You cannot scummy hashtag wisely, or the people's Mentor in today. We're going to talk about some powerful recruiting techniques for massive growth in your business and in your team, and so if you are new to this program, feel free to subscribe share with a friend do all the good things. I appreciate you guys. I love all you and if you haven't already go ahead and screenshot this bad boy put it in your Instagram story and I will repost and I've been doing all kinds of giveaways. So I appreciate you guys also, make sure you Review over on iTunes. There will be a fan of the Week on here and check my Instagram story at I mbos SLE within 24 hours this podcast. I will be giving away $50 $50 cashola US dollars to to one of you who left a review. So love you guys. Appreciate you guys. Let's Jump Right In  So I feel like if you're listening to this, you probably want to become a network marketing machine, right? So I'll just tell you that probably the most paid skill set aside from driving to events, which we can also talk about on the podcast for instance. That is you need to master how to sponsor how to build how to manage and how to grow your business and all I'm really saying is that yeah, your network marketing company might have great products. You might be an incredible retailer.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzh3Htxwht3i",
        "colab_type": "text"
      },
      "source": [
        "#Evaluation (Rouge 1, Rouge 2, Rouge L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oI7kDGMJi_Q",
        "colab_type": "text"
      },
      "source": [
        "##Post Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3GxkjKI1j-B",
        "colab_type": "text"
      },
      "source": [
        "Some generative summaries contain links and other fluff. Which could negatively impact rouge scores. It does seem like creator descriptions that contain links lead to auto summaries that also contain links. I will explore this further.\n",
        "\n",
        "This method helps to clean up the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT2aBBKVFlh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def post_process(string):\n",
        "  string = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', string)\n",
        "  string = re.sub(r'\\W+\\s', ' ', string)\n",
        "  return string\n",
        "  #remove duplicates?\n",
        "  # string = string.split()\n",
        "  # return \" \".join(sorted(set(string), key=words.index))\n",
        "\n",
        "results['t5_abstractive'] = results.apply(lambda row: post_process(row['t5_abstractive']), axis=1)\n",
        "results['supervised'] = results.apply(lambda row: post_process(row['supervised']), axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OS7CXegMD8p",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzH5JWKh5bZp",
        "colab_type": "text"
      },
      "source": [
        "My results are different from the baselines provided, however the same conclusions can still be reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKZHSad0hzoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "aea06ec0-c4d0-46c9-891b-d46e0ceb34ca"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTbxkpqcoEd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c8551bc2-c41d-4026-8752-527204bc1c78"
      },
      "source": [
        "results.columns.values"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['episode_id', 'episode_name', 'episode_description', 'transcript',\n",
              "       'textrank_summary', 'lexrank_summary', 'lsa_summary',\n",
              "       'semi_supervised', 'supervised', 'extractive', 't5_abstractive',\n",
              "       'first_five'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyYWn4ABm_a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "\n",
        "textrank = rouge.get_scores(results['episode_description'], results['textrank_summary'], avg=True)\n",
        "lexrank = rouge.get_scores(results['episode_description'], results['lexrank_summary'], avg=True)\n",
        "lsa = rouge.get_scores(results['episode_description'], results['lsa_summary'], avg=True)\n",
        "semi_supervised = rouge.get_scores(results['episode_description'], results['semi_supervised'], avg=True)\n",
        "supervised = rouge.get_scores(results['episode_description'], results['supervised'], avg=True)\n",
        "extractive = rouge.get_scores(results['episode_description'], results['extractive'], avg=True)\n",
        "t5_abstractive = rouge.get_scores(results['episode_description'], results['t5_abstractive'], avg=True)\n",
        "first_five = rouge.get_scores(results['episode_description'], results['first_five'], avg=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mefVdsfgncxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0f5e9572-d45b-410a-f9bc-247946e4d1c0"
      },
      "source": [
        "row_names = ['textrank', 'lexrank', 'lsa', 'semi_supervised', 'supervised', 'extractive', 't5_abstractive', 'first_five']\n",
        "rouge1_scores = [textrank['rouge-1']['f'], lexrank['rouge-1']['f'], lsa['rouge-1']['f'], semi_supervised['rouge-1']['f'], supervised['rouge-1']['f'], extractive['rouge-1']['f'], t5_abstractive['rouge-1']['f'], first_five['rouge-1']['f']]\n",
        "\n",
        "rouge1_df = pd.DataFrame({'Rouge1-F':rouge1_scores}, index=row_names)\n",
        "rouge1_df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rouge1-F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textrank</th>\n",
              "      <td>0.116462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexrank</th>\n",
              "      <td>0.119708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa</th>\n",
              "      <td>0.132847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semi_supervised</th>\n",
              "      <td>0.161447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supervised</th>\n",
              "      <td>0.221370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extractive</th>\n",
              "      <td>0.137192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5_abstractive</th>\n",
              "      <td>0.203084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_five</th>\n",
              "      <td>0.138515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Rouge1-F\n",
              "textrank         0.116462\n",
              "lexrank          0.119708\n",
              "lsa              0.132847\n",
              "semi_supervised  0.161447\n",
              "supervised       0.221370\n",
              "extractive       0.137192\n",
              "t5_abstractive   0.203084\n",
              "first_five       0.138515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc4dzgRBnmdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "864d0e2b-a931-4466-f4ac-16db403d271a"
      },
      "source": [
        "rouge2_scores = [textrank['rouge-2']['f'], lexrank['rouge-2']['f'], lsa['rouge-2']['f'], semi_supervised['rouge-2']['f'], supervised['rouge-2']['f'], extractive['rouge-2']['f'], t5_abstractive['rouge-2']['f'], first_five['rouge-2']['f']]\n",
        "\n",
        "rouge2_df = pd.DataFrame({'Rouge2-F':rouge2_scores}, index=row_names)\n",
        "rouge2_df"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rouge2-F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textrank</th>\n",
              "      <td>0.014054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexrank</th>\n",
              "      <td>0.014022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa</th>\n",
              "      <td>0.010752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semi_supervised</th>\n",
              "      <td>0.029776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supervised</th>\n",
              "      <td>0.091048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extractive</th>\n",
              "      <td>0.020735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5_abstractive</th>\n",
              "      <td>0.092811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_five</th>\n",
              "      <td>0.029270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Rouge2-F\n",
              "textrank         0.014054\n",
              "lexrank          0.014022\n",
              "lsa              0.010752\n",
              "semi_supervised  0.029776\n",
              "supervised       0.091048\n",
              "extractive       0.020735\n",
              "t5_abstractive   0.092811\n",
              "first_five       0.029270"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t6hSK3Or7xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "923c6c09-b3a9-4f5f-e6b4-2a840ca61f11"
      },
      "source": [
        "rougel_scores = [textrank['rouge-l']['f'], lexrank['rouge-l']['f'], lsa['rouge-l']['f'], semi_supervised['rouge-l']['f'], supervised['rouge-l']['f'], extractive['rouge-l']['f'], t5_abstractive['rouge-l']['f'], first_five['rouge-l']['f']]\n",
        "\n",
        "rougel_df = pd.DataFrame({'RougeL-F':rougel_scores}, index=row_names)\n",
        "rougel_df"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RougeL-F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textrank</th>\n",
              "      <td>0.104832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexrank</th>\n",
              "      <td>0.107688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa</th>\n",
              "      <td>0.109165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semi_supervised</th>\n",
              "      <td>0.146533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supervised</th>\n",
              "      <td>0.211520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extractive</th>\n",
              "      <td>0.116782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5_abstractive</th>\n",
              "      <td>0.226783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_five</th>\n",
              "      <td>0.126801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 RougeL-F\n",
              "textrank         0.104832\n",
              "lexrank          0.107688\n",
              "lsa              0.109165\n",
              "semi_supervised  0.146533\n",
              "supervised       0.211520\n",
              "extractive       0.116782\n",
              "t5_abstractive   0.226783\n",
              "first_five       0.126801"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE69-dnesXXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rouge_scores = rouge1_df.merge(rouge2_df, left_index=True, right_index = True)\n",
        "rouge_scores = rouge_scores.merge(rougel_df, left_index=True, right_index = True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VFDeIiuxjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "62c120f4-5df3-48b2-b984-1ec7bd489669"
      },
      "source": [
        "rouge_scores"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rouge1-F</th>\n",
              "      <th>Rouge2-F</th>\n",
              "      <th>RougeL-F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textrank</th>\n",
              "      <td>0.116462</td>\n",
              "      <td>0.014054</td>\n",
              "      <td>0.104832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexrank</th>\n",
              "      <td>0.119708</td>\n",
              "      <td>0.014022</td>\n",
              "      <td>0.107688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa</th>\n",
              "      <td>0.132847</td>\n",
              "      <td>0.010752</td>\n",
              "      <td>0.109165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semi_supervised</th>\n",
              "      <td>0.161447</td>\n",
              "      <td>0.029776</td>\n",
              "      <td>0.146533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supervised</th>\n",
              "      <td>0.221370</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.211520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extractive</th>\n",
              "      <td>0.137192</td>\n",
              "      <td>0.020735</td>\n",
              "      <td>0.116782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5_abstractive</th>\n",
              "      <td>0.203084</td>\n",
              "      <td>0.092811</td>\n",
              "      <td>0.226783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_five</th>\n",
              "      <td>0.138515</td>\n",
              "      <td>0.029270</td>\n",
              "      <td>0.126801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Rouge1-F  Rouge2-F  RougeL-F\n",
              "textrank         0.116462  0.014054  0.104832\n",
              "lexrank          0.119708  0.014022  0.107688\n",
              "lsa              0.132847  0.010752  0.109165\n",
              "semi_supervised  0.161447  0.029776  0.146533\n",
              "supervised       0.221370  0.091048  0.211520\n",
              "extractive       0.137192  0.020735  0.116782\n",
              "t5_abstractive   0.203084  0.092811  0.226783\n",
              "first_five       0.138515  0.029270  0.126801"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2zP57T7vTxE",
        "colab_type": "text"
      },
      "source": [
        "Note to self: On the 150 gold summaries, it quantitatively appears that the t5 model performs best, supervised bart is a very close second. Among the extractive techniques, the first five sentences approach performs best, closely followed by Bert + kmeans. However, remember that:\n",
        " \n",
        "\n",
        "*   the reference episode descriptions vary in quality (a good rouge score on a terrible reference is not ideal)\n",
        "*   Post processing has not yet been done on the results of abstractive models to clean up summaries where links and other fluff were generated. (This affects precision scores, and overall f1 score, then again some references contain links and other promotional material)\n",
        "*   Abstractive models were only trained on a subset of the data because of colab constraints (Bart: 5000, t5: 3000), maybe models would be more performant if fine-tuned on more samples\n",
        "*   For the t5 model, very long text was shortened to avoid using up all the RAM. Ideally, podcasters would talk about their content in the first few minutes of the episode but that might not always be the case. This could have also affected peformance\n",
        "*   Also need to test out a combination of the two summarization approaches (extractive + abstractive), maybe that could improve rouge scores?\n",
        "*   Summaries need to be a short, standalone, grammatically complete statement that helps the user decide if episode is worth a listen. It should be readable on a phone screen. (Some observed generative summaries, (and extractive) seem to have done well in this regard)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3bJ2gFs3Kqk",
        "colab_type": "text"
      },
      "source": [
        "Try/To do:\n",
        "\n",
        "\n",
        "*   Fine-tuning the BERT model used for the extractive technique\n",
        "*   Fine-tuning T5 and BART on more samples to see if that improves results\n",
        "*   Cleaning up generated summaries to remove links and other promotional content (reduces overall rouge scores)\n",
        "*   Evaluating the result of combining an extractive and abstractive model\n",
        "*   Pass in a fine-tuned t5 or Bart to the extractive pipeline and see (does not work)\n",
        "*   Would the extractive model have performed better if the threshold for final sentences was higher\n",
        "*   Coreference resolution with spacy\n",
        "\n"
      ]
    }
  ]
}